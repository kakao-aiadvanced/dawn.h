{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeVogERU3IL3sTqoG8ffq3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 3개의 블로그 포스팅 본문을 Load"],"metadata":{"id":"l7zuHXyxEWli"}},{"cell_type":"code","source":["# !pip install -q --upgrade langchain_community\n","# !pip install -qU langchain-text-splitters\n","# !pip install langchain-openai\n","# !pip install langchain-chroma\n","!pip install langchainhub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pw-FRCoBEXhd","executionInfo":{"status":"ok","timestamp":1718693873417,"user_tz":-540,"elapsed":10068,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"4df46a0a-8eb0-47bf-930e-5c074a451a89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchainhub\n","  Downloading langchainhub-0.1.20-py3-none-any.whl (5.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0)\n","Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n","  Downloading types_requests-2.32.0.20240602-py3-none-any.whl (15 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2024.6.2)\n","Installing collected packages: types-requests, langchainhub\n","Successfully installed langchainhub-0.1.20 types-requests-2.32.0.20240602\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Set the API key\n","os.environ['OPENAI_API_KEY'] = \"\""],"metadata":{"id":"YOrSTVqHGBMa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Step 1: Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4J9Z_QTEpUS","executionInfo":{"status":"ok","timestamp":1718692806196,"user_tz":-540,"elapsed":18938,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"843e78e2-f7f4-447c-da81-78be89542ff9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from langchain_community.document_loaders import WebBaseLoader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwiHgfyJEe30","executionInfo":{"status":"ok","timestamp":1718692936099,"user_tz":-540,"elapsed":776,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"df52c8bc-e322-49d3-d0ed-0a78fa837bc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]}]},{"cell_type":"code","source":["loader = WebBaseLoader([\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n","                        \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n","                        \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\"])\n","docs = loader.load()"],"metadata":{"id":"Brwi4qEtEqAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_engineering = docs[0].page_content\n","file_path = '/content/drive/MyDrive/Colab Notebooks/promptengineering.txt'\n","\n","with open(file_path, 'w') as file:\n","    file.write(prompt_engineering)\n","\n","print(f\"String saved to {file_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYzPG1zsFOj2","executionInfo":{"status":"ok","timestamp":1718699265434,"user_tz":-540,"elapsed":2,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"d12560d0-f2dd-460e-b5c3-91166df8e1b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["String saved to /content/drive/MyDrive/Colab Notebooks/promptengineering.txt\n"]}]},{"cell_type":"markdown","source":["### 불러온 본문을 Split (Chunking) : recursive text splitter 활용"],"metadata":{"id":"mAG0kwV3Fqe5"}},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","# Load example document\n","\n","# https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n","# promptengineering.txt 파일은 위 링크를 webbase loader 로 load 하여 사용\n","with open(\"/content/drive/MyDrive/Colab Notebooks/promptengineering.txt\") as f:\n","    prompt_engineering = f.read()\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    # Set a really small chunk size, just to show.\n","    chunk_size=100,\n","    chunk_overlap=50,\n","    length_function=len,\n","    is_separator_regex=False,\n",")\n","texts = text_splitter.create_documents([prompt_engineering])"],"metadata":{"id":"zwdX6uzgFg2k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  Chunks 를 임베딩하여 Vector store 저장: openai, chroma 사용"],"metadata":{"id":"Fj0ssQjtF5Lj"}},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings\n","\n","embeddings_model = OpenAIEmbeddings()"],"metadata":{"id":"8T1gRA_AF0fz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_chroma import Chroma\n","\n","# load it into Chroma\n","db = Chroma.from_documents(texts, embeddings_model)"],"metadata":{"id":"fsi2TQjZGgaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# query it\n","query = \"What is Chain-of-Thought\"\n","docs = db.similarity_search(query)\n","\n","# print results\n","print(docs[0].page_content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fItXr2aGynY","executionInfo":{"status":"ok","timestamp":1718699271406,"user_tz":-540,"elapsed":2,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"499b03f0-025f-4e7d-fe98-cddfead530c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u_b2FfQaHn3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### User query = ‘agent memory’ 를 받아 관련된 chunks를 retrieve"],"metadata":{"id":"fIB7Usw8HpnV"}},{"cell_type":"code","source":["from langchain import hub\n","\n","retriever = db.as_retriever()\n","prompt = hub.pull(\"rlm/rag-prompt\")"],"metadata":{"id":"AdEuGflWHra4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.chat_models import ChatOllama\n","from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"],"metadata":{"id":"Hdbmr3VBJCBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")\n","\n","relate_chunk = rag_chain.invoke(\"agent memory\")"],"metadata":{"id":"0Kpw6YqzIfAU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### User query와 retrieved chunk 에 대해 relevance 가 있는지를 평가하는 시스템 프롬프트 작성: retrieval 퀄리티를 LLM 이 스스로 평가하도록 하고, 관련이 있으면 {‘relevance’: ‘yes’} 관련이 없으면 {‘relevance’: ‘no’} 라고 출력하도록 함. ( JsonOutputParser() 를 활용 ) - llama3 prompt format 준수"],"metadata":{"id":"iq8a-_3aKnRW"}},{"cell_type":"code","source":["print(relate_chunk)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swUmVuckJSK5","executionInfo":{"status":"ok","timestamp":1718699273364,"user_tz":-540,"elapsed":3,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"0cca150e-f2e4-481a-e1fd-75c9ac162bc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Agent memory refers to the ability of an agent to remember past experiences and information in order to make decisions and take actions. This memory can be used to improve performance and adapt to changing environments. The agent's memory can store various types of information, such as goals, beliefs, perceptions, and actions.\n"]}]},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate\n","\n","template = \"You are a helpful assistant that check relevance based on chunk: {chunk}. related to: {question} \\n\"\n","prompt_relevance_check = ChatPromptTemplate.from_template(template)"],"metadata":{"id":"amyTvzhGK4RB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Literal\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","# Data model\n","class RelevenceCheck(BaseModel):\n","    \"\"\"determine if the chunk is relevant to answering the question..\"\"\"\n","\n","    relevance: Literal[\"yes\", \"no\"] = Field(\n","        ...,\n","        description=\"\"\"Given a retrieved text chunk and a question, determine if the chunk is relevant to answering the question. Relevance should be evaluated based on the following aspects:\n","- Does the chunk provide a direct answer to the question?\n","- Does the chunk contain information that is closely related to the question?\n","- Does the chunk help in understanding or further exploring the topic of the question?\n","\"\"\",)\n","\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n","structured_llm = llm.with_structured_output(RelevenceCheck)"],"metadata":{"id":"C3tHzMJJL0rq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_openai import ChatOpenAI\n","\n","\n","relevence_chain = (prompt_relevance_check |\n","                   structured_llm)"],"metadata":{"id":"NYFy_MSULOzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["relevence_chain.invoke({\"chunk\": relate_chunk, \"question\": \"What is the Agent Memory?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nBYRvkYO3b2","executionInfo":{"status":"ok","timestamp":1718699273824,"user_tz":-540,"elapsed":462,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"af9966f0-03c4-45a7-a8cb-ad8740485aa6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RelevenceCheck(relevance='yes')"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["relevence_chain.invoke({\"chunk\": relate_chunk, \"question\": \"I like apple\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XccEc9_gPWdw","executionInfo":{"status":"ok","timestamp":1718699274347,"user_tz":-540,"elapsed":525,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"17729c61-db12-43a6-cade-3f016e63f673"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RelevenceCheck(relevance='yes')"]},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","source":["### ‘yes’ 이고 7의 평가에서도 문제가 없다면, 4의 retrieved chunk 를 가지고 답변 작성"],"metadata":{"id":"CcFQigFRPzdY"}},{"cell_type":"code","source":["template = \"You are a helpful assistant please answer the question based on retrieved texts knowledge: {chunk}. question: {question} \\n\"\n","answer_template = ChatPromptTemplate.from_template(template)"],"metadata":{"id":"WMMsQV2gS5yC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ans_chain = answer_template | llm"],"metadata":{"id":"Z5gCxeAFPpsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lf0lgEp-c1ee"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def final_func(question):\n","  relate_chunk = rag_chain.invoke(question)\n","  relevence = relevence_chain.invoke({\"chunk\": relate_chunk, \"question\": question})\n","\n","  if \"no\" in relevence.relevance.lower():\n","      ### Logic here\n","      return \"not relevence\"\n","  elif \"yes\" in relevence.relevance.lower():\n","      answer = ans_chain.invoke({\"chunk\": relate_chunk, \"question\": question})\n","      return answer"],"metadata":{"id":"h-hQ87SSX5ag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["answer = final_func(\"What is the agent memory\")\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2Lj0j_LX-LK","executionInfo":{"status":"ok","timestamp":1718699307940,"user_tz":-540,"elapsed":3650,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"0e91ed71-f01b-4fbc-81ab-ab6f69dc244e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["content='The agent memory is the long-term memory that allows the agent to retain and recall information indefinitely. It serves as an external vector store that the agent can access when needed for queries.' response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 66, 'total_tokens': 102}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a1d4f4d1-d54b-468d-898a-ce1958be2f38-0' usage_metadata={'input_tokens': 66, 'output_tokens': 36, 'total_tokens': 102}\n"]}]},{"cell_type":"code","source":["answer.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"E-9KliMQdRJr","executionInfo":{"status":"ok","timestamp":1718699323106,"user_tz":-540,"elapsed":331,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"a9de5068-6c55-4ba4-a77e-d639b75637c4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The agent memory is the long-term memory that allows the agent to retain and recall information indefinitely. It serves as an external vector store that the agent can access when needed for queries.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["answer = final_func(\"I Like apple\")\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqROuc17dmp7","executionInfo":{"status":"ok","timestamp":1718699335784,"user_tz":-540,"elapsed":1677,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"82b82bff-60d2-4fc0-d846-2e0c28f1d6b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["not relevence\n"]}]},{"cell_type":"markdown","source":["### Runnablepaththrough를 이용해서 작성"],"metadata":{"id":"vGA5Mck1ky9v"}},{"cell_type":"code","source":["from langchain_core.runnables import RunnableBranch\n","\n","final_chain = (\n","    {\"chunk\": rag_chain, \"question\": RunnablePassthrough()}\n","    | RunnablePassthrough.assign(relevence=relevence_chain)\n","    | RunnableBranch(\n","        (lambda x: \"yes\" in x[\"relevence\"].relevance.lower(), ans_chain),\n","        (lambda x: \"no\" in x[\"relevence\"].relevance.lower(), RunnableLambda(lambda _: {\"content\":\"I don't know\"})),\n","        RunnableLambda(lambda _: {\"content\":\"I don't know\"})\n","    )\n",")"],"metadata":{"id":"ocYhyHYkdpgg","executionInfo":{"status":"ok","timestamp":1718702249188,"user_tz":-540,"elapsed":313,"user":{"displayName":"dawn h","userId":"01733870387110475686"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["final_chain.invoke(\"What is the agent memory\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RrbkO_kmioR","executionInfo":{"status":"ok","timestamp":1718702256353,"user_tz":-540,"elapsed":2611,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"02d0ac2e-dbd4-4a75-a1a3-4b74d83993b3"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='The agent memory is the long-term memory that allows the agent to retain and recall information infinitely. It serves as an external vector store that the agent can access during query time.', response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 65, 'total_tokens': 100}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8595f497-ee17-4988-843a-baeb96c0a968-0', usage_metadata={'input_tokens': 65, 'output_tokens': 35, 'total_tokens': 100})"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["final_chain.invoke(\"I like apple\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhTgwba4oFhD","executionInfo":{"status":"ok","timestamp":1718702267224,"user_tz":-540,"elapsed":1573,"user":{"displayName":"dawn h","userId":"01733870387110475686"}},"outputId":"8f0a8c62-39f8-4d75-ab98-95c7a4087dca"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'content': \"I don't know\"}"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":[],"metadata":{"id":"bvJtXGV1o1M_"},"execution_count":null,"outputs":[]}]}